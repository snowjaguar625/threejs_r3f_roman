{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n      }\n    };\n    return _extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    _extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.canMatchCharCode = exports.firstCharOptimizedIndices = exports.getOptimizedStartCodesIndices = exports.failedOptimizationPrefixMsg = void 0;\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\nvar every_1 = __importDefault(require(\"lodash/every\"));\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\nvar find_1 = __importDefault(require(\"lodash/find\"));\nvar values_1 = __importDefault(require(\"lodash/values\"));\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\nvar utils_1 = require(\"@chevrotain/utils\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar lexer_1 = require(\"./lexer\");\nvar complementErrorMessage = \"Complement Sets are not supported for first char optimization\";\nexports.failedOptimizationPrefixMsg = 'Unable to use \"first char\" lexer optimizations:\\n';\nfunction getOptimizedStartCodesIndices(regExp, ensureOptimizations) {\n  if (ensureOptimizations === void 0) {\n    ensureOptimizations = false;\n  }\n  try {\n    var ast = (0, reg_exp_parser_1.getRegExpAst)(regExp);\n    var firstChars = firstCharOptimizedIndices(ast.value, {}, ast.flags.ignoreCase);\n    return firstChars;\n  } catch (e) {\n    /* istanbul ignore next */\n    // Testing this relies on the regexp-to-ast library having a bug... */\n    // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        (0, utils_1.PRINT_WARNING)(\"\".concat(exports.failedOptimizationPrefixMsg) + \"\\tUnable to optimize: < \".concat(regExp.toString(), \" >\\n\") + \"\\tComplement Sets cannot be automatically optimized.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\");\n      }\n    } else {\n      var msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix = \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      (0, utils_1.PRINT_ERROR)(\"\".concat(exports.failedOptimizationPrefixMsg, \"\\n\") + \"\\tFailed parsing: < \".concat(regExp.toString(), \" >\\n\") + \"\\tUsing the regexp-to-ast library version: \".concat(regexp_to_ast_1.VERSION, \"\\n\") + \"\\tPlease open an issue at: https://github.com/bd82/regexp-to-ast/issues\" + msgSuffix);\n    }\n  }\n  return [];\n}\nexports.getOptimizedStartCodesIndices = getOptimizedStartCodesIndices;\nfunction firstCharOptimizedIndices(ast, result, ignoreCase) {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (var i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      var terms = ast.value;\n      for (var i = 0; i < terms.length; i++) {\n        var term = terms[i];\n        // skip terms that cannot effect the first char results\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n        var atom = term;\n        switch (atom.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            (0, forEach_1.default)(atom.value, function (code) {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                // range\n                var range = code;\n                // cannot optimize when ignoreCase is\n                if (ignoreCase === true) {\n                  for (var rangeCode = range.from; rangeCode <= range.to; rangeCode++) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                }\n                // Optimization (2 orders of magnitude less work for very large ranges)\n                else {\n                  // handle unoptimized values\n                  for (var rangeCode = range.from; rangeCode <= range.to && rangeCode < lexer_1.minOptimizationVal; rangeCode++) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                  // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                  if (range.to >= lexer_1.minOptimizationVal) {\n                    var minUnOptVal = range.from >= lexer_1.minOptimizationVal ? range.from : lexer_1.minOptimizationVal;\n                    var maxUnOptVal = range.to;\n                    var minOptIdx = (0, lexer_1.charCodeToOptimizedIndex)(minUnOptVal);\n                    var maxOptIdx = (0, lexer_1.charCodeToOptimizedIndex)(maxUnOptVal);\n                    for (var currOptIdx = minOptIdx; currOptIdx <= maxOptIdx; currOptIdx++) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n        // reached a mandatory production, no more **start** codes can be found on this alternative\n        var isOptionalQuantifier = atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n        if (\n        // A group may be optional due to empty contents /(?:)/\n        // or if everything inside it is optional /((a)?)/\n        atom.type === \"Group\" && isWholeOptional(atom) === false ||\n        // If this term is not a group it may only be optional if it has an optional quantifier\n        atom.type !== \"Group\" && isOptionalQuantifier === false) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n  // console.log(Object.keys(result).length)\n  return (0, values_1.default)(result);\n}\nexports.firstCharOptimizedIndices = firstCharOptimizedIndices;\nfunction addOptimizedIdxToResult(code, result, ignoreCase) {\n  var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\nfunction handleIgnoreCase(code, result) {\n  var char = String.fromCharCode(code);\n  var upperChar = char.toUpperCase();\n  /* istanbul ignore else */\n  if (upperChar !== char) {\n    var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    var lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(lowerChar.charCodeAt(0));\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\nfunction findCode(setNode, targetCharCodes) {\n  return (0, find_1.default)(setNode.value, function (codeOrRange) {\n    if (typeof codeOrRange === \"number\") {\n      return (0, includes_1.default)(targetCharCodes, codeOrRange);\n    } else {\n      // range\n      var range_1 = codeOrRange;\n      return (0, find_1.default)(targetCharCodes, function (targetCode) {\n        return range_1.from <= targetCode && targetCode <= range_1.to;\n      }) !== undefined;\n    }\n  });\n}\nfunction isWholeOptional(ast) {\n  var quantifier = ast.quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n  if (!ast.value) {\n    return false;\n  }\n  return (0, isArray_1.default)(ast.value) ? (0, every_1.default)(ast.value, isWholeOptional) : isWholeOptional(ast.value);\n}\nvar CharCodeFinder = /** @class */function (_super) {\n  __extends(CharCodeFinder, _super);\n  function CharCodeFinder(targetCharCodes) {\n    var _this = _super.call(this) || this;\n    _this.targetCharCodes = targetCharCodes;\n    _this.found = false;\n    return _this;\n  }\n  CharCodeFinder.prototype.visitChildren = function (node) {\n    // No need to keep looking...\n    if (this.found === true) {\n      return;\n    }\n    // switch lookaheads as they do not actually consume any characters thus\n    // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n    _super.prototype.visitChildren.call(this, node);\n  };\n  CharCodeFinder.prototype.visitCharacter = function (node) {\n    if ((0, includes_1.default)(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  };\n  CharCodeFinder.prototype.visitSet = function (node) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === undefined) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== undefined) {\n        this.found = true;\n      }\n    }\n  };\n  return CharCodeFinder;\n}(regexp_to_ast_1.BaseRegExpVisitor);\nfunction canMatchCharCode(charCodes, pattern) {\n  if (pattern instanceof RegExp) {\n    var ast = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n    var charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return (0, find_1.default)(pattern, function (char) {\n      return (0, includes_1.default)(charCodes, char.charCodeAt(0));\n    }) !== undefined;\n  }\n}\nexports.canMatchCharCode = canMatchCharCode;","map":null,"metadata":{},"sourceType":"script"}