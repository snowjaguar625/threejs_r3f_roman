{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\nvar lexer_1 = require(\"./lexer\");\nvar noop_1 = __importDefault(require(\"lodash/noop\"));\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\nvar last_1 = __importDefault(require(\"lodash/last\"));\nvar reject_1 = __importDefault(require(\"lodash/reject\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\nvar keys_1 = __importDefault(require(\"lodash/keys\"));\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nvar identity_1 = __importDefault(require(\"lodash/identity\"));\nvar assign_1 = __importDefault(require(\"lodash/assign\"));\nvar reduce_1 = __importDefault(require(\"lodash/reduce\"));\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\nvar utils_1 = require(\"@chevrotain/utils\");\nvar tokens_1 = require(\"./tokens\");\nvar lexer_errors_public_1 = require(\"./lexer_errors_public\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\nvar DEFAULT_LEXER_CONFIG = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nvar Lexer = /** @class */function () {\n  function Lexer(lexerDefinition, config) {\n    if (config === void 0) {\n      config = DEFAULT_LEXER_CONFIG;\n    }\n    var _this = this;\n    this.lexerDefinition = lexerDefinition;\n    this.lexerDefinitionErrors = [];\n    this.lexerDefinitionWarning = [];\n    this.patternIdxToConfig = {};\n    this.charCodeToPatternIdxToConfig = {};\n    this.modes = [];\n    this.emptyGroups = {};\n    this.trackStartLines = true;\n    this.trackEndLines = true;\n    this.hasCustom = false;\n    this.canModeBeOptimized = {};\n    // Duplicated from the parser's perf trace trait to allow future extraction\n    // of the lexer to a separate package.\n    this.TRACE_INIT = function (phaseDesc, phaseImpl) {\n      // No need to optimize this using NOOP pattern because\n      // It is not called in a hot spot...\n      if (_this.traceInitPerf === true) {\n        _this.traceInitIndent++;\n        var indent = new Array(_this.traceInitIndent + 1).join(\"\\t\");\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          console.log(\"\".concat(indent, \"--> <\").concat(phaseDesc, \">\"));\n        }\n        var _a = (0, utils_1.timer)(phaseImpl),\n          time = _a.time,\n          value = _a.value;\n        /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n        var traceMethod = time > 10 ? console.warn : console.log;\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          traceMethod(\"\".concat(indent, \"<-- <\").concat(phaseDesc, \"> time: \").concat(time, \"ms\"));\n        }\n        _this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    };\n    if (typeof config === \"boolean\") {\n      throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" + \"a boolean 2nd argument is no longer supported\");\n    }\n    // todo: defaults func?\n    this.config = (0, assign_1.default)({}, DEFAULT_LEXER_CONFIG, config);\n    var traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n    this.TRACE_INIT(\"Lexer Constructor\", function () {\n      var actualDefinition;\n      var hasOnlySingleMode = true;\n      _this.TRACE_INIT(\"Lexer Config handling\", function () {\n        if (_this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          _this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n        } else {\n          if (_this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n            throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n          }\n        }\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n        }\n        _this.trackStartLines = /full|onlyStart/i.test(_this.config.positionTracking);\n        _this.trackEndLines = /full/i.test(_this.config.positionTracking);\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if ((0, isArray_1.default)(lexerDefinition)) {\n          actualDefinition = {\n            modes: {\n              defaultMode: (0, clone_1.default)(lexerDefinition)\n            },\n            defaultMode: lexer_1.DEFAULT_MODE\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = (0, clone_1.default)(lexerDefinition);\n        }\n      });\n      if (_this.config.skipValidations === false) {\n        _this.TRACE_INIT(\"performRuntimeChecks\", function () {\n          _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.performRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n        _this.TRACE_INIT(\"performWarningRuntimeChecks\", function () {\n          _this.lexerDefinitionWarning = _this.lexerDefinitionWarning.concat((0, lexer_1.performWarningRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n      }\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {};\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      (0, forEach_1.default)(actualDefinition.modes, function (currModeValue, currModeName) {\n        actualDefinition.modes[currModeName] = (0, reject_1.default)(currModeValue, function (currTokType) {\n          return (0, isUndefined_1.default)(currTokType);\n        });\n      });\n      var allModeNames = (0, keys_1.default)(actualDefinition.modes);\n      (0, forEach_1.default)(actualDefinition.modes, function (currModDef, currModName) {\n        _this.TRACE_INIT(\"Mode: <\".concat(currModName, \"> processing\"), function () {\n          _this.modes.push(currModName);\n          if (_this.config.skipValidations === false) {\n            _this.TRACE_INIT(\"validatePatterns\", function () {\n              _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.validatePatterns)(currModDef, allModeNames));\n            });\n          }\n          // If definition errors were encountered, the analysis phase may fail unexpectedly/\n          // Considering a lexer with definition errors may never be used, there is no point\n          // to performing the analysis anyhow...\n          if ((0, isEmpty_1.default)(_this.lexerDefinitionErrors)) {\n            (0, tokens_1.augmentTokenTypes)(currModDef);\n            var currAnalyzeResult_1;\n            _this.TRACE_INIT(\"analyzeTokenTypes\", function () {\n              currAnalyzeResult_1 = (0, lexer_1.analyzeTokenTypes)(currModDef, {\n                lineTerminatorCharacters: _this.config.lineTerminatorCharacters,\n                positionTracking: config.positionTracking,\n                ensureOptimizations: config.ensureOptimizations,\n                safeMode: config.safeMode,\n                tracer: _this.TRACE_INIT\n              });\n            });\n            _this.patternIdxToConfig[currModName] = currAnalyzeResult_1.patternIdxToConfig;\n            _this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult_1.charCodeToPatternIdxToConfig;\n            _this.emptyGroups = (0, assign_1.default)({}, _this.emptyGroups, currAnalyzeResult_1.emptyGroups);\n            _this.hasCustom = currAnalyzeResult_1.hasCustom || _this.hasCustom;\n            _this.canModeBeOptimized[currModName] = currAnalyzeResult_1.canBeOptimized;\n          }\n        });\n      });\n      _this.defaultMode = actualDefinition.defaultMode;\n      if (!(0, isEmpty_1.default)(_this.lexerDefinitionErrors) && !_this.config.deferDefinitionErrorsHandling) {\n        var allErrMessages = (0, map_1.default)(_this.lexerDefinitionErrors, function (error) {\n          return error.message;\n        });\n        var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      }\n      // Only print warning if there are no errors, This will avoid pl\n      (0, forEach_1.default)(_this.lexerDefinitionWarning, function (warningDescriptor) {\n        (0, utils_1.PRINT_WARNING)(warningDescriptor.message);\n      });\n      _this.TRACE_INIT(\"Choosing sub-methods implementations\", function () {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (lexer_1.SUPPORT_STICKY) {\n          _this.chopInput = identity_1.default;\n          _this.match = _this.matchWithTest;\n        } else {\n          _this.updateLastIndex = noop_1.default;\n          _this.match = _this.matchWithExec;\n        }\n        if (hasOnlySingleMode) {\n          _this.handleModes = noop_1.default;\n        }\n        if (_this.trackStartLines === false) {\n          _this.computeNewColumn = identity_1.default;\n        }\n        if (_this.trackEndLines === false) {\n          _this.updateTokenEndLineColumnLocation = noop_1.default;\n        }\n        if (/full/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createFullToken;\n        } else if (/onlyStart/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createOffsetOnlyToken;\n        } else {\n          throw Error(\"Invalid <positionTracking> config option: \\\"\".concat(_this.config.positionTracking, \"\\\"\"));\n        }\n        if (_this.hasCustom) {\n          _this.addToken = _this.addTokenUsingPush;\n          _this.handlePayload = _this.handlePayloadWithCustom;\n        } else {\n          _this.addToken = _this.addTokenUsingMemberAccess;\n          _this.handlePayload = _this.handlePayloadNoCustom;\n        }\n      });\n      _this.TRACE_INIT(\"Failed Optimization Warnings\", function () {\n        var unOptimizedModes = (0, reduce_1.default)(_this.canModeBeOptimized, function (cannotBeOptimized, canBeOptimized, modeName) {\n          if (canBeOptimized === false) {\n            cannotBeOptimized.push(modeName);\n          }\n          return cannotBeOptimized;\n        }, []);\n        if (config.ensureOptimizations && !(0, isEmpty_1.default)(unOptimizedModes)) {\n          throw Error(\"Lexer Modes: < \".concat(unOptimizedModes.join(\", \"), \" > cannot be optimized.\\n\") + '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' + \"\\t Or inspect the console log for details on how to resolve these issues.\");\n        }\n      });\n      _this.TRACE_INIT(\"clearRegExpParserCache\", function () {\n        (0, reg_exp_parser_1.clearRegExpParserCache)();\n      });\n      _this.TRACE_INIT(\"toFastProperties\", function () {\n        (0, utils_1.toFastProperties)(_this);\n      });\n    });\n  }\n  Lexer.prototype.tokenize = function (text, initialMode) {\n    if (initialMode === void 0) {\n      initialMode = this.defaultMode;\n    }\n    if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n      var allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, function (error) {\n        return error.message;\n      });\n      var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n      throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n    }\n    return this.tokenizeInternal(text, initialMode);\n  };\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  Lexer.prototype.tokenizeInternal = function (text, initialMode) {\n    var _this = this;\n    var i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n    var orgText = text;\n    var orgLength = orgText.length;\n    var offset = 0;\n    var matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    var guessedNumberOfTokens = this.hasCustom ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n    : Math.floor(text.length / 10);\n    var matchedTokens = new Array(guessedNumberOfTokens);\n    var errors = [];\n    var line = this.trackStartLines ? 1 : undefined;\n    var column = this.trackStartLines ? 1 : undefined;\n    var groups = (0, lexer_1.cloneEmptyGroups)(this.emptyGroups);\n    var trackLines = this.trackStartLines;\n    var lineTerminatorPattern = this.config.lineTerminatorsPattern;\n    var currModePatternsLength = 0;\n    var patternIdxToConfig = [];\n    var currCharCodeToPatternIdxToConfig = [];\n    var modeStack = [];\n    var emptyArray = [];\n    Object.freeze(emptyArray);\n    var getPossiblePatterns;\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n    function getPossiblePatternsOptimized(charCode) {\n      var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(charCode);\n      var possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n    var pop_mode = function pop_mode(popToken) {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (modeStack.length === 1 &&\n      // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n      // So no error should occur.\n      popToken.tokenType.PUSH_MODE === undefined) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        var msg_1 = _this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg_1\n        });\n      } else {\n        modeStack.pop();\n        var newMode = (0, last_1.default)(modeStack);\n        patternIdxToConfig = _this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig = _this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        var modeCanBeOptimized = _this.canModeBeOptimized[newMode] && _this.config.safeMode === false;\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n    function push_mode(newMode) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n      currModePatternsLength = patternIdxToConfig.length;\n      var modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n    var currConfig;\n    var recoveryEnabled = this.config.recoveryEnabled;\n    while (offset < orgLength) {\n      matchedImage = null;\n      var nextCharCode = orgText.charCodeAt(offset);\n      var chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      var chosenPatternsLength = chosenPatternIdxToConfig.length;\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        var currPattern = currConfig.pattern;\n        payload = null;\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        var singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = currPattern.exec(orgText, offset, matchedTokens, groups);\n          if (match !== null) {\n            matchedImage = match[0];\n            if (match.payload !== undefined) {\n              payload = match.payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern, offset);\n          matchedImage = this.match(currPattern, text, offset);\n        }\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            var longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              var longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              var longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (match.payload !== undefined) {\n                    altPayload = match.payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern, offset);\n                matchAltImage = this.match(longerAltPattern, text, offset);\n              }\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n          this.handlePayload(newToken, payload);\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column, imageLength);\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          var numOfLTsInMatch = 0;\n          var foundTerminator = void 0;\n          var lastLTEndOffset = void 0;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n          if (numOfLTsInMatch !== 0) {\n            line = line + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset;\n            this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        var errorStartOffset = offset;\n        var errorLine = line;\n        var errorColumn = column;\n        var foundResyncPoint = recoveryEnabled === false;\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            var currConfig_1 = patternIdxToConfig[j];\n            var currPattern = currConfig_1.pattern;\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            var singleCharCode = currConfig_1.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig_1.isCustom === true) {\n              foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n            } else {\n              this.updateLastIndex(currPattern, offset);\n              foundResyncPoint = currPattern.exec(text) !== null;\n            }\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n        errLength = offset - errorStartOffset;\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        });\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    };\n  };\n  Lexer.prototype.handleModes = function (config, pop_mode, push_mode, newToken) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      var pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  };\n  Lexer.prototype.chopInput = function (text, length) {\n    return text.substring(length);\n  };\n  Lexer.prototype.updateLastIndex = function (regExp, newLastIndex) {\n    regExp.lastIndex = newLastIndex;\n  };\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  Lexer.prototype.updateTokenEndLineColumnLocation = function (newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n    var lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  };\n\n  Lexer.prototype.computeNewColumn = function (oldColumn, imageLength) {\n    return oldColumn + imageLength;\n  };\n  Lexer.prototype.createOffsetOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.createStartOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      startLine: startLine,\n      startColumn: startColumn,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.createFullToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine: startLine,\n      endLine: startLine,\n      startColumn: startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.addTokenUsingPush = function (tokenVector, index, tokenToAdd) {\n    tokenVector.push(tokenToAdd);\n    return index;\n  };\n  Lexer.prototype.addTokenUsingMemberAccess = function (tokenVector, index, tokenToAdd) {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  };\n  Lexer.prototype.handlePayloadNoCustom = function (token, payload) {};\n  Lexer.prototype.handlePayloadWithCustom = function (token, payload) {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  };\n  Lexer.prototype.matchWithTest = function (pattern, text, offset) {\n    var found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  };\n  Lexer.prototype.matchWithExec = function (pattern, text) {\n    var regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  };\n  Lexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" + \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n  Lexer.NA = /NOT_APPLICABLE/;\n  return Lexer;\n}();\nexports.Lexer = Lexer;","map":null,"metadata":{},"sourceType":"script"}